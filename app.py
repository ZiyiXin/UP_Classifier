# app.py
from flask import Flask, request, jsonify, render_template
import pandas as pd
import joblib
import numpy as np
from treeinterpreter import treeinterpreter as ti
from sklearn.pipeline import Pipeline

# ç‰¹å¾åˆ—é…ç½®ï¼ˆå’Œè®­ç»ƒä¿æŒä¸€è‡´ï¼‰
from analysis import FEATURE_COLS

app = Flask(__name__)

# ================== è·¯å¾„ ==================
CSV_PATH = "database/upfile_data_labeled.csv"
MODEL_PATH = "classifier/up_classifier_10dim.pkl"

# ================== å¸®åŠ©å‡½æ•° ==================
def bucket_from_percentile(p: float) -> str:
    """æ ¹æ®ç™¾åˆ†ä½ç»™åŒºé—´æ ‡ç­¾"""
    if p >= 80:
        return "Top 20%"
    elif p <= 20:
        return "Bottom 20%"
    return "Middle 60%"


def get_model_and_X_for_ti(clf, X_raw: np.ndarray):
    """
    ä¸º treeinterpreter æä¾›:
      - çº¯æ¨¡å‹åŸº learner (RandomForest / DecisionTree ç­‰)
      - é¢„å¤„ç†åçš„ç‰¹å¾çŸ©é˜µ X_for_ti

    æ”¯æŒ sklearn Pipelineï¼›è‹¥ clf ä¸æ˜¯ Pipelineï¼Œåˆ™ç›´æ¥è¿”å› clf å’Œ X_rawã€‚
    """
    if isinstance(clf, Pipeline):
        if len(clf.steps) > 1:
            # å‰é¢æ‰€æœ‰æ­¥éª¤è§†ä¸ºé¢„å¤„ç†
            preproc = clf[:-1]
            model = clf.steps[-1][1]
            X_for_ti = preproc.transform(X_raw)
        else:
            model = clf.steps[-1][1]
            X_for_ti = X_raw
    else:
        model = clf
        X_for_ti = X_raw

    return model, X_for_ti


# ================== åˆå§‹åŒ–ï¼šåŠ è½½æ•°æ® & æ¨¡å‹ & é¢„è®¡ç®—åˆ†æ•° ==================
print("[INIT] Loading CSV and model...")
df = pd.read_csv(CSV_PATH)
clf = joblib.load(MODEL_PATH)

# uid è½¬ä¸º int
df["uid"] = df["uid"].astype(int)

# ---- 1. åŸºç¡€ç‰¹å¾çŸ©é˜µ ----
X_all = df[FEATURE_COLS].values

# ---- 2. æ¨¡å‹é¢„æµ‹ï¼ˆpipeline ç›´æ¥ç”¨ï¼‰----
proba_all = clf.predict_proba(X_all)          # shape (n_samples, n_classes)
pred_labels_all = clf.predict(X_all)          # shape (n_samples,)

df["model_prob_high"] = proba_all[:, 1]       # ç±»åˆ« 1 = é«˜å•†ä¸šä»·å€¼
df["model_pred_label"] = pred_labels_all      # 0 = ä½, 1 = é«˜

# ---- 3. ç½®ä¿¡åº¦ï¼šæ¨¡å‹å¯¹è‡ªå·±é¢„æµ‹æ ‡ç­¾çš„æ¦‚ç‡ ----
df["confidence"] = np.where(
    df["model_pred_label"] == 1,
    df["model_prob_high"],       # é¢„æµ‹ä¸ºé«˜ä»·å€¼ â†’ ç”¨ P(high)
    1.0 - df["model_prob_high"]  # é¢„æµ‹ä¸ºä½ä»·å€¼ â†’ ç”¨ P(low) = 1 - P(high)
)

# ---- 4. å…¨å±€ SHAP èŒƒå›´ï¼ˆç”¨ treeinterpreterï¼‰----
print("[INIT] Computing global SHAP contributions...")
model_for_ti, X_for_ti = get_model_and_X_for_ti(clf, X_all)

prediction_all, bias_all, contrib_all = ti.predict(model_for_ti, X_for_ti)
# contrib_all å½¢çŠ¶é€šå¸¸æ˜¯ (n_samples, n_features, n_classes) æˆ– (n_samples, n_features)

if contrib_all.ndim == 3:
    # å–â€œé«˜ä»·å€¼â€è¿™ä¸€ç±»ï¼ˆå‡å®šç´¢å¼• 1ï¼‰ï¼Œå¦‚æœåªæœ‰ä¸€ä¸ªç±»åˆ™å– 0
    class_idx = 1 if contrib_all.shape[2] > 1 else 0
    contrib_class = contrib_all[:, :, class_idx]   # (n_samples, n_features)
elif contrib_all.ndim == 2:
    contrib_class = contrib_all                    # (n_samples, n_features)
else:
    raise ValueError(f"Unexpected contrib_all ndim: {contrib_all.ndim}")

# æ¯ä¸ªæ ·æœ¬çš„ SHAP æ€»å’Œ
shap_sums = contrib_class.sum(axis=1)              # (n_samples,)

SHAP_MIN = float(shap_sums.min())
SHAP_MAX = float(shap_sums.max())
print(f"[INIT] SHAP range: min={SHAP_MIN:.4f}, max={SHAP_MAX:.4f}")

df["shap_sum"] = shap_sums

if SHAP_MAX > SHAP_MIN:
    df["shap_norm"] = (df["shap_sum"] - SHAP_MIN) / (SHAP_MAX - SHAP_MIN)
else:
    # æç«¯æƒ…å†µï¼šæ‰€æœ‰æ ·æœ¬ SHAP å®Œå…¨ä¸€æ ·
    df["shap_norm"] = 0.5

# é™åˆ¶åœ¨ [0,1]
df["shap_norm"] = df["shap_norm"].clip(0.0, 1.0)

# ---- 5. ç»¼åˆå•†ä¸šä»·å€¼è¯„åˆ†ï¼šæ–¹æ³• C ----
# Score = 100 * (0.5 * confidence + 0.5 * shap_norm)
df["value_score"] = 100.0 * (0.5 * df["confidence"] + 0.5 * df["shap_norm"])

# ---- 6. åœ¨å…¨ä½“ UP ä¸­çš„è¯„åˆ†ç™¾åˆ†ä½ + åŒºé—´ ----
df["score_percentile"] = df["value_score"].rank(pct=True) * 100.0
df["score_bucket"] = df["score_percentile"].apply(bucket_from_percentile)

print("[INIT] Ready.")


# ================== é¡µé¢è·¯ç”± ==================
@app.route("/")
def home():
    return render_template("home.html")


@app.route("/dashboard")
def dashboard():
    uid = request.args.get("uid", "").strip()
    return render_template("dashboard.html", uid=uid)


# ================== API: å•ä¸ª UP ä¿¡æ¯ï¼ˆé¢„æµ‹ + ç»¼åˆè¯„åˆ†ï¼‰ ==================
@app.route("/api/predict/<uid>")
def api_predict(uid):
    uid = uid.strip()
    if not uid.isdigit():
        return jsonify({"success": False, "message": "Invalid UID"}), 400

    uid_int = int(uid)
    row_df = df[df["uid"] == uid_int]
    if row_df.empty:
        return jsonify({"success": False, "message": "UID not found"}), 404

    row = row_df.iloc[0]

    pred_label = int(row["model_pred_label"])
    prob_high = float(row["model_prob_high"])
    confidence = float(row["confidence"])
    value_score = float(row["value_score"])
    score_percentile = float(row["score_percentile"])
    score_bucket = row["score_bucket"]
    shap_sum = float(row["shap_sum"])
    shap_norm = float(row["shap_norm"])

    label_name = "é«˜å•†ä¸šä»·å€¼" if pred_label == 1 else "ä½å•†ä¸šä»·å€¼"

    return jsonify({
        "success": True,
        "uid": uid_int,
        "up_name": row.get("up_name", ""),
        "followers": int(row.get("followers", -1)),
        "prediction": {
            "label_binary": pred_label,
            "label_name": label_name,
            "prob_high": prob_high,
            "confidence": confidence,
            "value_score": value_score,      # â˜… å·²æ˜¯ç»¼åˆè¯„åˆ†
            "score_percentile": score_percentile,
            "score_bucket": score_bucket,
            "shap_sum": shap_sum,
            "shap_norm": shap_norm,
        },
        "features": {c: float(row[c]) for c in FEATURE_COLS}
    })


# ================== API: ä¼˜è´¨ UP ç»Ÿè®¡ï¼ˆä¸­ä½æ•° & æœ€å°å€¼ï¼‰ ==================
@app.route("/api/stats/good")
def good_stats():
    # ç”¨ä½ æ‰‹åŠ¨æ ‡æ³¨çš„ label_binary ä½œä¸ºâ€œä¼˜è´¨â€UP ä¾æ®
    good_df = df[df["label_binary"] == 1]

    median_vals = good_df[FEATURE_COLS].median().to_dict()
    min_vals = good_df[FEATURE_COLS].min().to_dict()

    return jsonify({
        "median": median_vals,
        "min": min_vals
    })


# ================== API: å•†ä¸šä»·å€¼å¤„æ–¹è§£é‡Š ==================
@app.route("/api/prescription/<uid>")
def api_prescription(uid):
    uid = uid.strip()
    if not uid.isdigit():
        return jsonify({"success": False, "message": "Invalid UID"}), 400

    uid_int = int(uid)
    row_df = df[df["uid"] == uid_int]
    if row_df.empty:
        return jsonify({"success": False, "message": "UID not found"}), 404

    row = row_df.iloc[0]

    # æ„é€ è¾“å…¥
    x_raw = np.array([[row[c] for c in FEATURE_COLS]])

    # å–å¾—é€‚ç”¨äº treeinterpreter çš„æ¨¡å‹ & ç‰¹å¾
    model_for_ti, x_for_ti = get_model_and_X_for_ti(clf, x_raw)

    try:
        prediction, bias, contributions = ti.predict(model_for_ti, x_for_ti)
        contrib_arr = contributions[0]   # é’ˆå¯¹å½“å‰è¿™ä¸€ä¸ªæ ·æœ¬

        if contrib_arr.ndim == 2:
            class_idx = 1 if contrib_arr.shape[1] > 1 else 0
            contrib_arr = contrib_arr[:, class_idx]  # (n_features,)
        # å¦‚æœæ˜¯ (n_features,) åˆ™ä¿æŒä¸å˜

    except Exception as e:
        return jsonify({
            "success": False,
            "uid": uid_int,
            "message": f"Failed to compute contributions: {e}"
        }), 500

    contrib_dict = {
        FEATURE_COLS[i]: float(contrib_arr[i])
        for i in range(len(FEATURE_COLS))
    }

    # å½“å‰æ ·æœ¬çš„ SHAP æ€»å’Œ + å½’ä¸€åŒ–
    shap_sum = float(contrib_arr.sum())
    if SHAP_MAX > SHAP_MIN:
        shap_norm = (shap_sum - SHAP_MIN) / (SHAP_MAX - SHAP_MIN)
    else:
        shap_norm = 0.5
    shap_norm = float(np.clip(shap_norm, 0.0, 1.0))

    # -----------------------------
    # ğŸ€ è‡ªåŠ¨ç”Ÿæˆè‡ªç„¶è¯­è¨€æå‡å»ºè®®
    # -----------------------------
    suggestions = []
    for feat, contrib in contrib_dict.items():

        if contrib < -0.02:  # æ˜æ˜¾è´Ÿå‘
            suggestions.append(
                f"ã€{feat}ã€‘ å¯¹å•†ä¸šä»·å€¼é€ æˆè´Ÿå‘å½±å“ï¼ˆ{contrib:.3f}ï¼‰ã€‚å»ºè®®é‡ç‚¹ä¼˜åŒ–ã€‚"
            )
        elif contrib > 0.02:  # æ˜æ˜¾æ­£å‘
            suggestions.append(
                f"ã€{feat}ã€‘ å½“å‰è¡¨ç°è¾ƒå¥½ï¼ˆè´¡çŒ® {contrib:.3f}ï¼‰ã€‚å»ºè®®ä¿æŒã€‚"
            )
        else:
            suggestions.append(
                f"ã€{feat}ã€‘ å½±å“è¾ƒå¼±ï¼ˆ{contrib:.3f}ï¼‰ï¼Œå¯æ ¹æ®ä¸šåŠ¡ç­–ç•¥çµæ´»è°ƒæ•´ã€‚"
            )

    return jsonify({
        "success": True,
        "uid": uid_int,
        "shap_sum": shap_sum,
        "shap_norm": shap_norm,
        "contributions": contrib_dict,
        "suggestions": suggestions
    })


# ================== å¯åŠ¨ ==================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)